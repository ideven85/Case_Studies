{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 6.390 Fall 2024 Homework 8\n",
    "**If you haven't already, please hit :**\n",
    "\n",
    "`File` -> `Save a Copy in Drive`\n",
    "\n",
    "**to copy this notebook to your Google drive, and work on a copy. If you don't do this, your changes won't be saved!**"
   ],
   "metadata": {
    "id": "USxWiWVJmnAk"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **RUN THIS NOTEBOOK WITH GPU**\n",
    "\n",
    "OTHERWISE YOU WILL SPEND A LONG TIME ON TRAINING\n",
    "\n",
    "**To do this, go to `Runtime` > `Change runtime type` and under `hardware acceleration` set the dropdown to `GPU`.**"
   ],
   "metadata": {
    "id": "xDKhQRzMo4KZ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As a reminder, we have <a href=\"https://introml.mit.edu/fall24/info/pytorch_overview\">this note on PyTorch</a> for more information about how to use it."
   ],
   "metadata": {
    "id": "lO2EKpT247B4"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Boilerplate\n",
    "\n",
    "Run the following cells to load the data. No need to edit anything here."
   ],
   "metadata": {
    "id": "-BRqHXMhYDsc"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ruGoFiTOK5qU"
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "# To get the MNIST (digit images) dataset\n",
    "from keras.datasets import mnist\n",
    "\n",
    "torch.manual_seed(0)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Download MNIST Data\n",
    "(mnist_train, labels_train), (mnist_test, labels_test) = mnist.load_data()\n",
    "\n",
    "# Load data as Numpy arrays of size (#datapoints, 28*28=784)\n",
    "mnist_train = mnist_train.astype(\"float32\") / 255.0\n",
    "mnist_test = mnist_test.astype(\"float32\") / 255.0\n",
    "mnist_train = mnist_train.reshape((len(mnist_train), np.prod(mnist_train.shape[1:])))\n",
    "mnist_test = mnist_test.reshape((len(mnist_test), np.prod(mnist_test.shape[1:])))\n",
    "\n",
    "# Split test data into a test and validation set:\n",
    "val_data = mnist_test[: (mnist_test.shape[0] // 2), :]\n",
    "test_data = mnist_test[(mnist_test.shape[0] // 2) :, :]\n",
    "train_data = mnist_train\n",
    "\n",
    "val_labels = labels_test[: (mnist_test.shape[0] // 2)]\n",
    "test_labels = labels_test[(mnist_test.shape[0] // 2) :]\n",
    "train_labels = labels_train\n",
    "\n",
    "# Display dataset information\n",
    "print(\"Downloaded the following data:\")\n",
    "print(\n",
    "    f\"train_data has shape {train_data.shape}, containing {train_data.shape[0]} images represented as ({train_data.shape[1]}, 1) vectors\"\n",
    ")\n",
    "print(\n",
    "    f\"val_data has shape {val_data.shape}, containing {val_data.shape[0]} images represented as ({val_data.shape[1]}, 1) vectors\"\n",
    ")\n",
    "print(\n",
    "    f\"test_data has shape {test_data.shape}, containing {test_data.shape[0]} images represented as ({test_data.shape[1]}, 1) vectors\"\n",
    ")"
   ],
   "metadata": {
    "id": "XFWZgbx0H0p5"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# We'll create a Dataset class to use with PyTorch's Built-In Dataloaders\n",
    "class MNISTDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A custom dataset class to use with PyTorch's built-in dataloaders.\n",
    "    This will make feeding images to our models much easier downstream.\n",
    "\n",
    "    data: np.arrays downloaded from Keras' databases\n",
    "    vectorize: if True, outputed image data will be (784,)\n",
    "                   if False, outputed image data will be (28,28)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, labels, vectorize=True):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.vectorize = vectorize\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_data = self.data[idx, :]\n",
    "        image_data = image_data.reshape((1, 28, 28))\n",
    "        if self.vectorize:\n",
    "            image_data = image_data.reshape((784,))\n",
    "        image_label = self.labels[idx]\n",
    "        return image_data, image_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "\n",
    "# Create MNISTDataset objects for each of our train/val/test sets\n",
    "train_dataset = MNISTDataset(train_data, train_labels)\n",
    "val_dataset = MNISTDataset(val_data, val_labels)\n",
    "test_dataset = MNISTDataset(test_data, test_labels)\n",
    "\n",
    "# Create a PyTorch dataloader for each train/val/test set\n",
    "# We'll use a batch size of 256 for the rest of this assignment.\n",
    "train_loader = DataLoader(train_dataset, batch_size=256)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256)\n",
    "\n",
    "# Create another dataset that doesn't reshape data\n",
    "cnn_train_dataset = MNISTDataset(train_data, train_labels, vectorize=False)\n",
    "cnn_val_dataset = MNISTDataset(val_data, val_labels, vectorize=False)\n",
    "cnn_test_dataset = MNISTDataset(test_data, test_labels, vectorize=False)\n",
    "\n",
    "# create new dataloaders without data reshaping\n",
    "cnn_train_loader = DataLoader(cnn_train_dataset, batch_size=256)\n",
    "cnn_val_loader = DataLoader(cnn_val_dataset, batch_size=256)\n",
    "cnn_test_loader = DataLoader(cnn_test_dataset, batch_size=256)\n",
    "\n",
    "# Display dataloader info\n",
    "print(\"Created the following Dataloaders:\")\n",
    "print(f\"train_loader has {len(train_loader)} batches of training data\")\n",
    "print(f\"val_loader has {len(val_loader)} batches of validation data\")\n",
    "print(f\"test_loader has {len(test_loader)} batches of testing data\")"
   ],
   "metadata": {
    "id": "OKSRa30PIFwB"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Defining a checker function so you can submit to the course website.\n",
    "def get_modules(module_object):\n",
    "    \"\"\"\n",
    "    gets a list of modules without nn.Sequential groupings, as a list of strings\n",
    "    \"\"\"\n",
    "    modules_list = []\n",
    "    for module in module_object.children():\n",
    "        if isinstance(module, nn.Sequential):\n",
    "            modules_list += get_modules(module)\n",
    "        else:\n",
    "            modules_list.append(str(module))\n",
    "    return modules_list"
   ],
   "metadata": {
    "id": "yrDKujSndu1D"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Image Classification"
   ],
   "metadata": {
    "id": "ekbipMUDB89j"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train/test scripts\n",
    "\n",
    "We'll first implement the functions to `train` and `test` our classifiers. We've written most of the functions for you. Your job is to fill in the calculation of the loss.\n",
    "\n",
    "As a reminder: For our loss function we will be using categorical cross-entropy loss between the output of our  model and our ground truth labels.\n",
    "\n",
    "Note that:\n",
    "* Use a built-in module instead of implementing the loss yourself!\n",
    "* We are expecting a one-line solution in each case. Don't overthink this!\n",
    "* The line you fill in for both `train()` and `test()` should be the same."
   ],
   "metadata": {
    "id": "KFszeEXtZz41"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# EDIT ME!\n",
    "\n",
    "\n",
    "def train(model, device, train_loader, optimizer, val_loader=None, pbar=False):\n",
    "    \"\"\"\n",
    "    Function for training our networks. One call to train() performs a single\n",
    "    epoch for training.\n",
    "\n",
    "    model: an instance of our model, in this assignment, this will be your autoencoder\n",
    "\n",
    "    device: either \"cpu\" or \"cuda\", depending on if you're running with GPU support\n",
    "\n",
    "    train_loader: the dataloader for the training set\n",
    "\n",
    "    optimizer: optimizer used for training (the optimizer implements SGD)\n",
    "\n",
    "    val_loader: (optional) validation set to include\n",
    "    \"\"\"\n",
    "\n",
    "    # Set the model to training mode.\n",
    "    model.train()\n",
    "\n",
    "    # we'll keep adding the loss of each batch to total_loss, so we can calculate\n",
    "    # the average loss at the end of the epoch.\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_items = 0\n",
    "\n",
    "    # We'll iterate through each batch. One call of train() trains for 1 epoch.\n",
    "    # batch_idx: an integer representing which batch number we're on\n",
    "    # input: a pytorch tensor representing a batch of input images.\n",
    "    if pbar:\n",
    "        train_loader = tqdm(train_loader)\n",
    "\n",
    "    for batch_idx, (input, target) in enumerate(train_loader):\n",
    "        # This line sends data to GPU if you're using a GPU\n",
    "        input = input.to(device)\n",
    "        target = target.type(torch.LongTensor).to(device)\n",
    "\n",
    "        # Zero out gradients from previous iteration\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # feed our input through the network\n",
    "        output = model.forward(input)\n",
    "\n",
    "        ## TODO: YOUR CODE HERE\n",
    "\n",
    "        loss_function = None  # FILL IN!\n",
    "        loss_value = loss_function  # ( FILL IN! )\n",
    "\n",
    "        ## END YOUR CODE\n",
    "\n",
    "        # Perform backprop\n",
    "        loss_value.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # accumulate loss to later calculate the average\n",
    "        total_loss += loss_value\n",
    "        total_correct += torch.sum(torch.argmax(output, dim=1) == target)\n",
    "        total_items += input.shape[0]\n",
    "\n",
    "    return total_loss.item() / len(train_loader), (total_correct / total_items).item()"
   ],
   "metadata": {
    "id": "WZgFftmIIJBa"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# EDIT ME!\n",
    "def test(model, device, test_loader, pbar=False):\n",
    "    \"\"\"\n",
    "    Function for testing our models. One call to test() runs through every\n",
    "    datapoint in our dataset once.\n",
    "\n",
    "    model: an instance of our model, in this assignment, this will be your autoencoder\n",
    "\n",
    "    device: either \"cpu\" or \"cuda:0\", depending on if you're running with GPU support\n",
    "\n",
    "    test_loader: the dataloader for the data to run the model on\n",
    "    \"\"\"\n",
    "    # set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # we'll keep track of total loss to calculate the average later\n",
    "    test_loss = 0\n",
    "    total_correct = 0\n",
    "    total_items = 0\n",
    "\n",
    "    # donâ€™t track gradients in testing, since no backprop\n",
    "    with torch.no_grad():\n",
    "        # iterate thorugh each test image\n",
    "        if pbar:\n",
    "            test_loader = tqdm(test_loader)\n",
    "\n",
    "        for input, target in test_loader:\n",
    "\n",
    "            # send input image to GPU if using GPU\n",
    "            input = input.to(device)\n",
    "            target = target.type(torch.LongTensor).to(device)\n",
    "\n",
    "            # run input through our model\n",
    "            output = model(input)\n",
    "\n",
    "            ## TODO: YOUR CODE HERE\n",
    "\n",
    "            loss_function = None  # FILL IN!\n",
    "            loss_value = loss_function  # ( FILL IN! )\n",
    "\n",
    "            ## END YOUR CODE\n",
    "\n",
    "            # Accumulate for accuracy\n",
    "            test_loss += loss_value\n",
    "            total_correct += torch.sum(torch.argmax(output, dim=1) == target)\n",
    "            total_items += input.shape[0]\n",
    "\n",
    "    # calculate average loss/accuracy per batch\n",
    "    test_loss /= len(test_loader)\n",
    "    accuracy = total_correct / total_items\n",
    "\n",
    "    return test_loss.item(), accuracy.item()"
   ],
   "metadata": {
    "id": "L1eoHP01IRqQ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fully Connected Classifiers\n",
    "\n",
    "The code box below will be modified to use various fully-connected architectures for the following questions.\n",
    "\n",
    "You will need to design your own `layers`, for example `layers=[nn.Linear(in_features=64, out_features=4)]` defines a single layer with 64 inputs and 4 output units."
   ],
   "metadata": {
    "id": "ZJXD7j3PbbAn"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# EDIT ME!\n",
    "\n",
    "# define the layers of our model\n",
    "layers = [\n",
    "    ## TODO: YOUR CODE HERE\n",
    "]\n",
    "\n",
    "# set number of epochs to train for\n",
    "epochs = 1  ## Change me in problem 5.3\n",
    "\n",
    "# check if running on CPU or GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# initialize a fully-connected classifier\n",
    "fc_model = nn.Sequential(*layers).to(device)\n",
    "\n",
    "# initialize our optimizer. We'll use Adam\n",
    "optimizer = torch.optim.Adam(fc_model.parameters())\n",
    "\n",
    "# train your classifier\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss, train_acc = train(fc_model, device, train_loader, optimizer)\n",
    "    val_loss, val_acc = test(fc_model, device, val_loader)\n",
    "    print(\n",
    "        \"Train Epoch: {:02d} \\tTraining Loss: {:.6f} \\tTraining Acc: {:.6f}\\n \\t\\t\\tValidation Loss: {:.6f} \\tValidation Acc: {:.6f}\\n\".format(\n",
    "            epoch, train_loss, train_acc, val_loss, val_acc\n",
    "        )\n",
    "    )\n",
    "\n",
    "# test your model\n",
    "test_loss, test_acc = test(fc_model, device, test_loader)\n",
    "print(\"\\n\\t\\t\\tTest Loss: {:.6f} \\t Test Accuracy: {:.6f}\".format(test_loss, test_acc))"
   ],
   "metadata": {
    "id": "5zP6B3GSIUvC"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convolutional Classifier\n",
    "\n",
    "The code box below will be modified to use for convolutional neural network architectures. Note that the code is slightly different, using a different dataloader that doesn't flatten/vectorize the images."
   ],
   "metadata": {
    "id": "S1sgzqBDcRtZ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# EDIT ME!\n",
    "\n",
    "# check if running on CPU or GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# define the layers of our model\n",
    "layers = [\n",
    "    ## TODO: YOUR CODE HERE\n",
    "]\n",
    "\n",
    "# initialize a CNN classifier\n",
    "cnn_model = nn.Sequential(*layers).to(device)\n",
    "\n",
    "# initialize our optimizer. We'll use Adam\n",
    "optimizer = torch.optim.Adam(cnn_model.parameters())\n",
    "\n",
    "# set number of epochs to train for\n",
    "epochs = 1\n",
    "\n",
    "# train your classifier\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss, train_acc = train(cnn_model, device, cnn_train_loader, optimizer)\n",
    "    val_loss, val_acc = test(cnn_model, device, cnn_val_loader)\n",
    "    print(\n",
    "        \"Train Epoch: {:02d} \\tTraining Loss: {:.6f} \\tTraining Acc: {:.6f} \\tValidation Loss: {:.6f} \\tValidation Acc: {:.6f}\".format(\n",
    "            epoch, train_loss, train_acc, val_loss, val_acc\n",
    "        )\n",
    "    )\n",
    "\n",
    "# test your model\n",
    "test_loss, test_acc = test(cnn_model, device, cnn_test_loader)\n",
    "print(\"\\nTest Loss: {:.6f} \\t Test Accuracy: {:.6f}\".format(test_loss, test_acc))"
   ],
   "metadata": {
    "id": "cAcRJYrQccMj"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}