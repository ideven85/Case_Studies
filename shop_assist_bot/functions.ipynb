{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-27T17:55:52.872213Z",
     "start_time": "2025-12-27T17:55:52.838317Z"
    }
   },
   "source": [
    "from jupyter_client.session import extract_header\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEU\"))\n",
    "# 1print(\"\\n\" + response.output_text)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T14:28:43.784683Z",
     "start_time": "2025-12-27T14:28:43.774319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_completions_functional(model=\"gpt-4\", **kwargs):\n",
    "\n",
    "    return client.responses.create(model=model, **kwargs)"
   ],
   "id": "50f58ab595f3211a",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T14:55:32.413593Z",
     "start_time": "2025-12-27T14:55:32.402267Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# . Define a list of callable tools for the model\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"name\": \"get_horoscope\",\n",
    "        \"description\": \"Get today's horoscope for an astrological sign.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"sign\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"An astrological sign like Taurus or Aquarius\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"sign\"],\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "def get_horoscope(sign):\n",
    "    return f\"{sign}: Next Tuesday you will befriend a baby otter.\""
   ],
   "id": "cb01eb2c9e948ae8",
   "outputs": [],
   "execution_count": 108
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T14:55:33.080150Z",
     "start_time": "2025-12-27T14:55:33.070822Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_list = [{\"role\": \"user\", \"content\": \"What is my horoscope? I am an Aquarius.\"}]"
   ],
   "id": "493018f19038ea40",
   "outputs": [],
   "execution_count": 109
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T14:55:40.934586Z",
     "start_time": "2025-12-27T14:55:34.136096Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a running input list we will add to over time\n",
    "\n",
    "# 2. Prompt the model with tools defined\n",
    "\n",
    "response = get_completions_functional(\n",
    "    model=\"gpt-4\", tools=tools, temperature=0, input=input_list\n",
    ")\n",
    "# Save function call outputs for subsequent requests"
   ],
   "id": "322ebb6a17dba84c",
   "outputs": [],
   "execution_count": 110
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T14:55:41.960887Z",
     "start_time": "2025-12-27T14:55:41.934866Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "list(zip(response.model_dump().keys(), response.model_dump().values()))"
   ],
   "id": "a71d4664bea93e54",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', 'resp_01fde4fbfe1d8b0c00694ff36787fc81a0833fa63626958b81'),\n",
       " ('created_at', 1766847336.0),\n",
       " ('error', None),\n",
       " ('incomplete_details', None),\n",
       " ('instructions', None),\n",
       " ('metadata', {}),\n",
       " ('model', 'gpt-4-0613'),\n",
       " ('object', 'response'),\n",
       " ('output',\n",
       "  [{'arguments': '{\\n  \"sign\": \"Aquarius\"\\n}',\n",
       "    'call_id': 'call_CgOnTN8li0p4ePm6KcXfGvqK',\n",
       "    'name': 'get_horoscope',\n",
       "    'type': 'function_call',\n",
       "    'id': 'fc_01fde4fbfe1d8b0c00694ff36a556081a08cee8eda684df409',\n",
       "    'status': 'completed'}]),\n",
       " ('parallel_tool_calls', True),\n",
       " ('temperature', 0.0),\n",
       " ('tool_choice', 'auto'),\n",
       " ('tools',\n",
       "  [{'name': 'get_horoscope',\n",
       "    'parameters': {'type': 'object',\n",
       "     'properties': {'sign': {'type': 'string',\n",
       "       'description': 'An astrological sign like Taurus or Aquarius'}},\n",
       "     'required': ['sign'],\n",
       "     'additionalProperties': False},\n",
       "    'strict': True,\n",
       "    'type': 'function',\n",
       "    'description': \"Get today's horoscope for an astrological sign.\"}]),\n",
       " ('top_p', 1.0),\n",
       " ('background', False),\n",
       " ('conversation', None),\n",
       " ('max_output_tokens', None),\n",
       " ('max_tool_calls', None),\n",
       " ('previous_response_id', None),\n",
       " ('prompt', None),\n",
       " ('prompt_cache_key', None),\n",
       " ('reasoning', {'effort': None, 'generate_summary': None, 'summary': None}),\n",
       " ('safety_identifier', None),\n",
       " ('service_tier', 'default'),\n",
       " ('status', 'completed'),\n",
       " ('text', {'format': {'type': 'text'}, 'verbosity': 'medium'}),\n",
       " ('top_logprobs', 0),\n",
       " ('truncation', 'disabled'),\n",
       " ('usage',\n",
       "  {'input_tokens': 69,\n",
       "   'input_tokens_details': {'cached_tokens': 0},\n",
       "   'output_tokens': 18,\n",
       "   'output_tokens_details': {'reasoning_tokens': 0},\n",
       "   'total_tokens': 87}),\n",
       " ('user', None),\n",
       " ('billing', {'payer': 'developer'}),\n",
       " ('completed_at', 1766847339),\n",
       " ('prompt_cache_retention', None),\n",
       " ('store', True)]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 111
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T14:55:44.200532Z",
     "start_time": "2025-12-27T14:55:44.174702Z"
    }
   },
   "cell_type": "code",
   "source": "response.output",
   "id": "e7302f475522e519",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ResponseFunctionToolCall(arguments='{\\n  \"sign\": \"Aquarius\"\\n}', call_id='call_CgOnTN8li0p4ePm6KcXfGvqK', name='get_horoscope', type='function_call', id='fc_01fde4fbfe1d8b0c00694ff36a556081a08cee8eda684df409', status='completed')]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 112
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T14:55:50.232248Z",
     "start_time": "2025-12-27T14:55:50.220158Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_list += response.output"
   ],
   "id": "41783daf276710ce",
   "outputs": [],
   "execution_count": 113
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T14:55:51.359078Z",
     "start_time": "2025-12-27T14:55:51.341507Z"
    }
   },
   "cell_type": "code",
   "source": "input_list",
   "id": "63770180a862e629",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'What is my horoscope? I am an Aquarius.'},\n",
       " ResponseFunctionToolCall(arguments='{\\n  \"sign\": \"Aquarius\"\\n}', call_id='call_CgOnTN8li0p4ePm6KcXfGvqK', name='get_horoscope', type='function_call', id='fc_01fde4fbfe1d8b0c00694ff36a556081a08cee8eda684df409', status='completed')]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 114
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T14:55:53.501734Z",
     "start_time": "2025-12-27T14:55:53.493727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = response.output[0].model_dump()"
   ],
   "id": "6ba95f1d415ef90d",
   "outputs": [],
   "execution_count": 115
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T14:55:54.188771Z",
     "start_time": "2025-12-27T14:55:54.168823Z"
    }
   },
   "cell_type": "code",
   "source": "x",
   "id": "5e16dd8501d96010",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arguments': '{\\n  \"sign\": \"Aquarius\"\\n}',\n",
       " 'call_id': 'call_CgOnTN8li0p4ePm6KcXfGvqK',\n",
       " 'name': 'get_horoscope',\n",
       " 'type': 'function_call',\n",
       " 'id': 'fc_01fde4fbfe1d8b0c00694ff36a556081a08cee8eda684df409',\n",
       " 'status': 'completed'}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 116
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T14:55:57.545354Z",
     "start_time": "2025-12-27T14:55:57.530493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x[\"name\"] += get_horoscope(x[\"arguments\"])"
   ],
   "id": "c0a3999839d0e132",
   "outputs": [],
   "execution_count": 117
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T14:55:59.198702Z",
     "start_time": "2025-12-27T14:55:59.172609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x[\"name\"]"
   ],
   "id": "74ac0f01bcc77304",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'get_horoscope{\\n  \"sign\": \"Aquarius\"\\n}: Next Tuesday you will befriend a baby otter.'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 118
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T14:56:07.040256Z",
     "start_time": "2025-12-27T14:56:07.029333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "horoscope = json.dumps(get_horoscope(json.loads(x[\"arguments\"])))\n",
    "\n",
    "input_list.append(\n",
    "    {\"type\": \"function_call_output\", \"call_id\": x[\"call_id\"], \"output\": horoscope}\n",
    ")"
   ],
   "id": "f0304caa7f6bb489",
   "outputs": [],
   "execution_count": 119
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T14:13:15.972813Z",
     "start_time": "2025-12-27T14:13:15.948425Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import json\n",
    "# for item in response.output:\n",
    "#     if item.type == \"function_call\":\n",
    "#         if item.name == \"get_horoscope\":\n",
    "#             # 3. Execute the function logic for get_horoscope\n",
    "#             horoscope = get_horoscope(json.loads(item.arguments))\n",
    "#             print(horoscope)\n",
    "#             # 4. Provide function call results to the model\n",
    "#             input_list.append({\n",
    "#                 \"type\": \"function_call_output\",\n",
    "#                 \"call_id\": item.call_id,\n",
    "#                 \"output\": json.dumps({\n",
    "#                   \"horoscope\": horoscope\n",
    "#                 })\n",
    "#             })"
   ],
   "id": "62602b05ef42bb51",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sign': 'Aquarius'}: Next Tuesday you will befriend a baby otter.\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T14:56:15.684471Z",
     "start_time": "2025-12-27T14:56:15.660242Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Final input:\")\n",
    "print(input_list)"
   ],
   "id": "19d26c07a80a86f1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final input:\n",
      "[{'role': 'user', 'content': 'What is my horoscope? I am an Aquarius.'}, ResponseFunctionToolCall(arguments='{\\n  \"sign\": \"Aquarius\"\\n}', call_id='call_CgOnTN8li0p4ePm6KcXfGvqK', name='get_horoscope', type='function_call', id='fc_01fde4fbfe1d8b0c00694ff36a556081a08cee8eda684df409', status='completed'), {'type': 'function_call_output', 'call_id': 'call_CgOnTN8li0p4ePm6KcXfGvqK', 'output': '\"{\\'sign\\': \\'Aquarius\\'}: Next Tuesday you will befriend a baby otter.\"'}]\n"
     ]
    }
   ],
   "execution_count": 120
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T14:56:33.761903Z",
     "start_time": "2025-12-27T14:56:21.984959Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = client.responses.create(\n",
    "    model=\"gpt-5\",\n",
    "    instructions=\"Respond only with a horoscope generated by a tool.\",\n",
    "    tools=tools,\n",
    "    input=input_list,\n",
    ")\n",
    "\n",
    "# 5. The model should be able to give a response!"
   ],
   "id": "e2062cdbe33e6921",
   "outputs": [],
   "execution_count": 121
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T14:56:37.450166Z",
     "start_time": "2025-12-27T14:56:37.425627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Final output:\")\n",
    "print(response.model_dump_json(indent=2))"
   ],
   "id": "4831d26b145da576",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final output:\n",
      "{\n",
      "  \"id\": \"resp_01fde4fbfe1d8b0c00694ff396442481a0b1bc91a26700a75e\",\n",
      "  \"created_at\": 1766847382.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": \"Respond only with a horoscope generated by a tool.\",\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-5-2025-08-07\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"rs_01fde4fbfe1d8b0c00694ff397e58481a0959d13fc59e1747b\",\n",
      "      \"summary\": [],\n",
      "      \"type\": \"reasoning\",\n",
      "      \"content\": null,\n",
      "      \"encrypted_content\": null,\n",
      "      \"status\": null\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"msg_01fde4fbfe1d8b0c00694ff3a149b881a0891a6b651da36f41\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"annotations\": [],\n",
      "          \"text\": \"{'sign': 'Aquarius'}: Next Tuesday you will befriend a baby otter.\",\n",
      "          \"type\": \"output_text\",\n",
      "          \"logprobs\": []\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [\n",
      "    {\n",
      "      \"name\": \"get_horoscope\",\n",
      "      \"parameters\": {\n",
      "        \"type\": \"object\",\n",
      "        \"properties\": {\n",
      "          \"sign\": {\n",
      "            \"type\": \"string\",\n",
      "            \"description\": \"An astrological sign like Taurus or Aquarius\"\n",
      "          }\n",
      "        },\n",
      "        \"required\": [\n",
      "          \"sign\"\n",
      "        ],\n",
      "        \"additionalProperties\": false\n",
      "      },\n",
      "      \"strict\": true,\n",
      "      \"type\": \"function\",\n",
      "      \"description\": \"Get today's horoscope for an astrological sign.\"\n",
      "    }\n",
      "  ],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": false,\n",
      "  \"conversation\": null,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": null,\n",
      "  \"prompt\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": \"medium\",\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"default\",\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": \"medium\"\n",
      "  },\n",
      "  \"top_logprobs\": 0,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 136,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 409,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 384\n",
      "    },\n",
      "    \"total_tokens\": 545\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"billing\": {\n",
      "    \"payer\": \"developer\"\n",
      "  },\n",
      "  \"completed_at\": 1766847393,\n",
      "  \"prompt_cache_retention\": null,\n",
      "  \"store\": true\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 122
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T14:56:39.545925Z",
     "start_time": "2025-12-27T14:56:39.522635Z"
    }
   },
   "cell_type": "code",
   "source": "print(len(response.output))",
   "id": "143290462a493f92",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "execution_count": 123
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T14:56:41.741672Z",
     "start_time": "2025-12-27T14:56:41.721710Z"
    }
   },
   "cell_type": "code",
   "source": "response.output[1].model_dump()",
   "id": "b41d6cacb26a814d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'msg_01fde4fbfe1d8b0c00694ff3a149b881a0891a6b651da36f41',\n",
       " 'content': [{'annotations': [],\n",
       "   'text': \"{'sign': 'Aquarius'}: Next Tuesday you will befriend a baby otter.\",\n",
       "   'type': 'output_text',\n",
       "   'logprobs': []}],\n",
       " 'role': 'assistant',\n",
       " 'status': 'completed',\n",
       " 'type': 'message'}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 124
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T14:56:52.156987Z",
     "start_time": "2025-12-27T14:56:52.137508Z"
    }
   },
   "cell_type": "code",
   "source": "response.output_text",
   "id": "c00ae6886d81de44",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'sign': 'Aquarius'}: Next Tuesday you will befriend a baby otter.\""
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 125
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T17:04:27.960782Z",
     "start_time": "2025-12-27T17:04:27.951360Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@retry(wait=wait_random_exponential(multiplier=1, max=40), stop=stop_after_attempt(3))\n",
    "def chat_completion_request(messages, tools=None, tool_choice=None, model=\"gpt-4\"):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            tool_choice=tool_choice,\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(\"Unable to generate ChatCompletion response\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        return e"
   ],
   "id": "9d36823ac2f71afa",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T17:10:41.248757Z",
     "start_time": "2025-12-27T17:10:41.236169Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"name\": \"get_weather\",\n",
    "        \"description\": \"Retrieves current weather for the given location.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"City and country e.g. BogotÃ¡, Colombia\",\n",
    "                },\n",
    "                \"units\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                    \"description\": \"Units the temperature will be returned in.\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"location\", \"units\"],\n",
    "            \"additionalProperties\": False,\n",
    "        },\n",
    "        \"strict\": True,\n",
    "    }\n",
    "]"
   ],
   "id": "7ece85901fe15af3",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T18:46:09.794325Z",
     "start_time": "2025-12-27T18:46:09.754081Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class GetCurrentWeather(BaseModel):\n",
    "    \"\"\"\n",
    "    Get the current weather for a specific location.\n",
    "    The user can ask for any location, so infer the location from the user's prompt.\n",
    "    \"\"\"\n",
    "\n",
    "    location: str = Field(description=\"The city and state, e.g. San Francisco, CA\")\n",
    "    unit: str = Field(\n",
    "        description=\"The temperature unit to use. Infer this from the user's location, default is 'fahrenheit'\",\n",
    "        default=\"fahrenheit\",\n",
    "    )"
   ],
   "id": "696fd2233c558b45",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T18:47:42.038934Z",
     "start_time": "2025-12-27T18:47:41.051566Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt = [{\"role\": \"user\", \"content\": \"Give weather for Noida, India\"}]\n",
    "response = client.responses.parse(model=\"gpt-4\", text_format=GetCurrentWeather)"
   ],
   "id": "9a9286b871f2285d",
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"Invalid parameter: 'text.format' of type 'json_schema' is not supported with model version `gpt-4`.\", 'type': 'invalid_request_error', 'param': 'text.format', 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      1\u001b[39m prompt = [{\n\u001b[32m      2\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      3\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m current weather for the given location in \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m      6\u001b[39m      \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mGive weather for Noida, India\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      7\u001b[39m }]\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresponses\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-4\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtext_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mGetCurrentWeather\u001b[49m\n\u001b[32m     12\u001b[39m \n\u001b[32m     13\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ML_AI/lib/python3.12/site-packages/openai/resources/responses/responses.py:1129\u001b[39m, in \u001b[36mResponses.parse\u001b[39m\u001b[34m(self, text_format, background, conversation, include, input, instructions, max_output_tokens, max_tool_calls, metadata, model, parallel_tool_calls, previous_response_id, prompt, prompt_cache_key, reasoning, safety_identifier, service_tier, store, stream, stream_options, temperature, text, tool_choice, tools, top_logprobs, top_p, truncation, user, verbosity, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1122\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparser\u001b[39m(raw_response: Response) -> ParsedResponse[TextFormatT]:\n\u001b[32m   1123\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parse_response(\n\u001b[32m   1124\u001b[39m         input_tools=tools,\n\u001b[32m   1125\u001b[39m         text_format=text_format,\n\u001b[32m   1126\u001b[39m         response=raw_response,\n\u001b[32m   1127\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1129\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1130\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/responses\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1131\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1132\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1133\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbackground\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackground\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1134\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconversation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconversation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1135\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1136\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1137\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minstructions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1138\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_output_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_output_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1139\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1140\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1141\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1142\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1143\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprevious_response_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprevious_response_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1144\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1145\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1146\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1147\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1148\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1149\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1150\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1151\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1152\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1153\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1154\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1155\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1156\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1157\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1158\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtruncation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1159\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1160\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1161\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mResponseCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1163\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1166\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# we turn the `Response` instance into a `ParsedResponse`\u001b[39;49;00m\n\u001b[32m   1172\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# in the `parser` function above\u001b[39;49;00m\n\u001b[32m   1173\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mType\u001b[49m\u001b[43m[\u001b[49m\u001b[43mParsedResponse\u001b[49m\u001b[43m[\u001b[49m\u001b[43mTextFormatT\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mResponse\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1174\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ML_AI/lib/python3.12/site-packages/openai/_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ML_AI/lib/python3.12/site-packages/openai/_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'error': {'message': \"Invalid parameter: 'text.format' of type 'json_schema' is not supported with model version `gpt-4`.\", 'type': 'invalid_request_error', 'param': 'text.format', 'code': None}}"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T18:05:09.267902Z",
     "start_time": "2025-12-27T18:05:09.259922Z"
    }
   },
   "cell_type": "code",
   "source": [
    "content = response.output_parsed"
   ],
   "id": "5db2c51aa6041ffe",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T18:05:18.427798Z",
     "start_time": "2025-12-27T18:05:18.399542Z"
    }
   },
   "cell_type": "code",
   "source": "content",
   "id": "39b52fc03848ee17",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GetWeather(location='Noida, India', units='metric')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def call_function(name, args):\n",
    "    if name == \"get_weather\":\n",
    "        return get_weather(**args)\n",
    "    if name == \"send_email\":\n",
    "        return send_email(**args)"
   ],
   "id": "bb0e58a1060ac4e5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for tool_call in response.output:\n",
    "    if tool_call.type != \"function_call\":\n",
    "        continue\n",
    "\n",
    "    name = tool_call.name\n",
    "    args = json.loads(tool_call.arguments)\n",
    "\n",
    "    result = call_function(name, args)\n",
    "    input_messages.append(\n",
    "        {\n",
    "            \"type\": \"function_call_output\",\n",
    "            \"call_id\": tool_call.call_id,\n",
    "            \"output\": str(result),\n",
    "        }\n",
    "    )"
   ],
   "id": "8fc9cf04c6be37c6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
